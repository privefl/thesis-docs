<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Defense</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">




class: title-slide

background-image: url("figures/defense-cover.png")
background-position: center top
background-size: contain

---

class: center middle inverse

# Introduction &amp; Motivation

### Data, applications and research interest 

---

## Data

&lt;br&gt;

**Matrices** of Single Nucleotide Polymorphisms (SNPs, DNA mutations)

counting the number of alternative alleles (**0, 1, or 2**) 

for each individual (row) and each genome position (column)

&lt;br&gt;

\+ some phenotype(s) (e.g. disease status you want to predict)

\+ other metadata 

&lt;br&gt;

`$$\boxed{\Large{\text{Disease} \sim \text{DNA mutations} + \cdots}}$$`

---

## From genome-wide association studies (GWAS)&lt;br&gt;to polygenic risk scores (PRS)

&lt;br&gt;


&lt;img src="figures/gwas-height-20K.png" width="95%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

`$$PRS_i = \sum_{\substack{j \in S \\ p_j~&lt;~p_T}} \hat\beta_j \cdot G_{i,j}$$`

---

## Polygenic Risk Scores (PRS) for epidemiology

&lt;br&gt;

**One application: to provide evidence** for a polygenic contribution to a trait or a shared polygenic relationship between traits.

&lt;br&gt;

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/genomic-profile.png" alt="&amp;lt;small&amp;gt;Source: 10.1111/jcpp.12295&amp;lt;/small&amp;gt;" width="90%" /&gt;
&lt;p class="caption"&gt;&lt;small&gt;Source: 10.1111/jcpp.12295&lt;/small&gt;&lt;/p&gt;
&lt;/div&gt;

---

## Polygenic Risk Scores (PRS) for epidemiology

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/purcell2009.png" alt="&amp;lt;small&amp;gt;Source: 10.1038/nature08185&amp;lt;/small&amp;gt;" width="75%" /&gt;
&lt;p class="caption"&gt;&lt;small&gt;Source: 10.1038/nature08185&lt;/small&gt;&lt;/p&gt;
&lt;/div&gt;

---

## Polygenic Risk Scores (PRS) for predictive medicine

### Another application: to identify high risk individuals

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/high-risk.jpg" alt="&amp;lt;small&amp;gt;Source: 10.1038/s41576-018-0018-x&amp;lt;/small&amp;gt;" width="85%" /&gt;
&lt;p class="caption"&gt;&lt;small&gt;Source: 10.1038/s41576-018-0018-x&lt;/small&gt;&lt;/p&gt;
&lt;/div&gt;

---

## Interest in prediction: polygenic risk scores (PRS)

- Wray, Naomi R., Michael E. Goddard, and Peter M. Visscher. "**Prediction of individual genetic risk** to disease from genome-wide association studies." Genome research 17.10 (**2007**): 1520-1528.

- Wray, Naomi R., et al. "Pitfalls of **predicting complex traits** from SNPs." Nature Reviews Genetics 14.7 (**2013**): 507.

- Dudbridge, Frank. "Power and **predictive accuracy of polygenic risk scores**." PLoS genetics 9.3 (**2013**): e1003348.

- Chatterjee, Nilanjan, Jianxin Shi, and Montserrat García-Closas. "Developing and evaluating **polygenic risk prediction** models for stratified disease prevention." Nature Reviews Genetics 17.7 (**2016**): 392.

- Martin, Alicia R., et al. "Human demographic history impacts **genetic risk prediction** across diverse populations." The American Journal of Human Genetics 100.4 (**2017**): 635-649.

.footnote2[Still a gap between current predictions and clinical utility.&lt;/br&gt;Need more optimal predictions + larger sample sizes.]


---

## Very large genotype matrices

- previously: 15K x 280K, [celiac disease](https://doi.org/10.1038/ng.543) (~30GB)

- currently: 500K x 500K, [UK Biobank](https://doi.org/10.1101/166298) (~2TB)
 
&lt;img src="https://media.giphy.com/media/3o7bueyxGydy48Lwgo/giphy.gif" width="55%" style="display: block; margin: auto;" /&gt;

.footnote[But I still want to use <i class="fab  fa-r-project "></i>..]

---

class: center, middle, inverse

# How to analyze large genomic data?

&lt;br&gt;

### **Privé, F.**, Aschard, H., Ziyatdinov, A., &amp; Blum, M. G.B. (2018). Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr. Bioinformatics, 34(16), 2781-2787.

---

## Our two R packages: bigstatsr and bigsnpr

### Statistical tools with big matrices stored on disk

&lt;br&gt;

&lt;a href="https://doi.org/10.1093/bioinformatics/bty185" target="_blank"&gt;
&lt;img src="figures/bty185.png" width="70%" style="display: block; margin: auto;" /&gt;
&lt;/a&gt;

&lt;br&gt;

- {bigstatsr} for many types of matrix, to be used by any field of research

- {bigsnpr} for functions that are specific to the analysis of genetic data


&lt;br&gt;

Package {bigstatsr} provides fast PCA, association and predictive models, etc.

---

## The solution I found

&lt;img src="https://raw.githubusercontent.com/privefl/RR18/master/memory-solution.svg?sanitize=true" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Format `FBM` is very similar to format `filebacked.big.matrix` from package {bigmemory} (details in [this vignette](https://privefl.github.io/bigstatsr/articles/bigstatsr-and-bigmemory.html)).]

---

## Multiple association testing

The idea behind Genome-Wide Association Studies (GWAS) is simple: test each variant one by one for association with the phenotype of interest.
For a continuous phenotype (e.g. height), linear regression is used and a t-test is performed for each SNP `\(j\)` on `\(\beta^{(j)}\)` where
`$$\hat{y} = \alpha^{(j)} + \beta^{(j)} SNP^{(j)} + \gamma_1^{(j)} COV_1 + \cdots + \gamma_K^{(j)} COV_K~,$$`
and `\(K\)` is the number of covariables, including **first principal components** and other covariates such as age and gender. 

Similarly, for a binary phenotype (e.g. disease status), logistic regression is used and a Z-test is performed for each SNP `\(j\)` on `\(\beta^{(j)}\)` where
`$$\log{\left(\frac{\hat{p}}{1-\hat{p}}\right)} = \alpha^{(j)} + \beta^{(j)} SNP^{(j)} + \gamma_1^{(j)} COV_1 + \cdots + \gamma_K^{(j)} COV_K~,$$`
and `\(\hat{p} = \mathbb{P}(Y = 1)\)` and `\(Y\)` denotes the binary phenotype.

---

### Which DNA mutations are associated with one disease?

&lt;br&gt;

&lt;br&gt;

&lt;img src="figures/gwas-height-20K.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Partial Singular Value Decomposition

15K `\(\times\)` 100K -- 10 first PCs -- 6 cores -- **1 min** (vs 2h in base R)

&lt;/br&gt;

&lt;img src="https://raw.githubusercontent.com/privefl/RR18/master/PC1-4.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[Implemented in `big_randomSVD()`, powered by R packages {RSpectra} and {Rcpp}.]

---

## Benchmarks (GWAS)

&lt;img src="figures/table-bench.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## Precision (approximate PCA)

&lt;img src="figures/approx-pca.png" width="80%" style="display: block; margin: auto;" /&gt;

---

class: center, middle, inverse

# How to predict disease status&lt;br&gt;based on genotypes?

---

## Standard PRS - part 1: estimating effects

### Genome-wide association studies (GWAS)

In a GWAS, each single-nucleotide polymorphism (SNP) is tested **independently**, resulting in one **effect size** `\(\hat\beta\)` and one **p-value** `\(p\)` for each SNP. 

&lt;img src="figures/gwas-height-20K.png" width="95%" style="display: block; margin: auto;" /&gt;

Easy combining: `\(PRS_i = \sum_j \hat\beta_j \cdot G_{i,j}\)`

---

## Standard PRS - part 2: restricting predictors

### &lt;span style="color:#38761D"&gt;Clumping&lt;/span&gt; + &lt;span style="color:#1515FF"&gt;Thresholding&lt;/span&gt; ("C+T" or just "PRS")

&lt;br&gt;

&lt;img src="figures/GWAS2PRS3.png" width="100%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

`$$PRS_i = \sum_{\substack{j \in S_\text{clumping} \\ p_j~&lt;~p_T}} \hat\beta_j \cdot G_{i,j}$$`

---

## A more optimal approach to computing PRS?

In C+T: weights learned independently and heuristics for correlation and regularization.

#### Statistical learning

- joint models of all SNPs at once

- use regularization to account for correlated and null effects

- already proved useful in the litterature (Abraham et al. 2013; Okser et al. 2014; Spiliopoulou et al. 2015)

#### Our contribution

- a memory- and computation-efficient implementation to be used for biobank-scale data

- an automatic choice of the regularization hyper-parameter

- a comprehensive comparison for different disease architectures

---

## Penalized Logistic Regression (PLR)

&lt;br&gt;

&lt;Small&gt;$$\arg\!\min_{\beta_0,~\beta}(\lambda, \alpha)\left\{  \underbrace{ -\sum_{i=1}^n \left( y_i \log\left(p_i\right) + (1 - y_i) \log\left(1 - p_i\right) \right) }_\text{Loss function}   +   \underbrace{ \lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization}  \right\}$$&lt;/Small&gt;

&lt;br&gt;

***

- `\(p_i=1/\left(1+\exp\left(-(\beta_0 + x_i^T\beta)\right)\right)\)`

- `\(x\)` is denoting the genotypes and covariables (e.g. principal components), 

- `\(y\)` is the disease status we want to predict, 

- `\(\lambda\)` is a regularization parameter that needs to be determined and

- `\(\alpha\)` determines relative parts of the regularization `\(0 \le \alpha \le 1\)`. 

---

### Prediction with PLR is improving faster


&lt;img src="figures/pres-AUC-ntrain2.svg" width="80%" style="display: block; margin: auto;" /&gt;

.foonote["Efficient implementation of penalized regression for genetic risk prediction" -- under revision]

---

## Real data

&lt;br&gt;

#### Celiac disease

- intolerance to gluten

- only treatment: gluten-free diet

- heritability: 57-87% (Nisticò et al. 2006)

- prevalence: 1-6%

&lt;br&gt;

#### Case-control study for the celiac disease (WTCCC, Dubois et al. 2010)

- ~15,000 individuals

- ~280,000 SNPs

- ~30% cases

---

### Results: real Celiac phenotypes

&lt;img src="figures/results-celiac2.png" width="95%" style="display: block; margin: auto;" /&gt;

&lt;img src="figures/celiac-roc3.svg" width="55%" style="display: block; margin: auto;" /&gt;

---

## LASSO for predicting height

- 350K individuals x 656K SNPs in less than one day

- Within each sex category, 65.5% of correlation between predicted and true height (56% with C+T-max)

&lt;img src="https://privefl.github.io/blog/images/UKB-final-pred.png" width="70%" style="display: block; margin: auto;" /&gt;


---

class: center, middle, inverse

# Using summary statistics

---

## Standard PRS: C+T

In a GWAS, each SNP is tested independently, resulting in one **effect size** `\(\hat\beta\)` and one **p-value** `\(p\)` for each SNP (**summary statistics**). 

&lt;br&gt;

&lt;img src="figures/gwas-height-20K.png" width="85%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

`$$PRS_i = \sum_{\substack{j \in S_\text{clumping} \\ p_j~&lt;~p_T}} \hat\beta_j \cdot G_{i,j}$$`

---

## Predictive methods based on summary statistics

&lt;br&gt;

When you have only summary statistics (and a small reference panel), you can use:

- C+T

- LDpred (*Vilhjálmsson, Bjarni J., et al. "Modeling linkage disequilibrium increases accuracy of polygenic risk scores." The American Journal of Human Genetics 97.4 (2015): 576-592*).

- lassosum (*Mak, Timothy Shin Heng, et al. "Polygenic scores via penalized regression on summary statistics." Genetic epidemiology 41.6 (2017): 469-480.*)

- NPS (*Chun, Sung, et al. "Non-parametric polygenic risk prediction using partitioned GWAS summary statistics." bioRxiv (2018): 370064.*)

&lt;br&gt;

The idea of LDpred, lassosum and NPS is to use a reference panel to **account for correlation** between SNPs, instead of pruning (removing) SNPs. Lassosum also adds some sparsity.

---

## Could those models be improved?


- take into account quality of imputation?

&lt;img src="figures/imputation.png" width="50%" style="display: block; margin: auto;" /&gt;

- support PLINK bed files only; what about BGEN files such as for the UK Biobank?

- scalable to which extent?

- combine with individual-level datasets? (of possibly different populations)

---

# Stacked Clumping and Thresholding (SCT)

## Making the most of C+T for polygenic scores

&lt;br&gt;

### Florian Privé

---

## Standard PRS - part 1: estimating effects

### Genome-wide association studies (GWAS)

In a GWAS, each single-nucleotide polymorphism (SNP) is tested **independently**, resulting in one **effect size** `\(\hat\beta\)` and one **p-value** `\(p\)` for each SNP. 

&lt;img src="figures/gwas-height-20K.png" width="95%" style="display: block; margin: auto;" /&gt;

Easy combining: `\(PRS_i = \sum_j \hat\beta_j \cdot G_{i,j}\)`

---

## Standard PRS - part 2: restricting predictors

### &lt;span style="color:#38761D"&gt;Clumping&lt;/span&gt; + &lt;span style="color:#1515FF"&gt;Thresholding&lt;/span&gt; (C+T)

&lt;br&gt;

&lt;img src="figures/GWAS2PRS3.png" width="100%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

`$$PRS_i = \sum_{\substack{j \in S_\text{clumping} \\ p_j~&lt;~p_T}} \hat\beta_j \cdot G_{i,j}$$`

---

## Hyper-parameters in C+T

- threshold on squared correlation of clumping ( `\(r_c^2 \sim 0.2\)` ) and    
window size for LD computation ( `\(w_c \sim 500 kb\)` )

- p-value threshold ( `\(p_T\)` between `\(1\)` and `\(10^{-8}\)` and choose the best one )

--

- threshold of imputation quality score ( `\(INFO_T \sim 0.3\)` )

--

`\(\Longrightarrow\)` *stdCT* (standard C+T)

&lt;br&gt;

--

#### Our contribution

- an efficient implementation to compute many C+T scores for different hyper-parameters (5600 sets of hyper-parameters `\(\times\)` 22 chromosomes)    
`\(\Longrightarrow\)` *maxCT* (maximized C+T)

--

- going further by stacking all C+T models (instead of just choosing the best model)    
`\(\Longrightarrow\)` *SCT* (Stacked C+T)

---

## Stacking with penalized logistic regression

&lt;br&gt;

&lt;Small&gt;$$\arg\!\min_{\beta_0,~\beta}(\lambda, \alpha)\left\{  \underbrace{ -\sum_{i=1}^n \left( y_i \log\left(p_i\right) + (1 - y_i) \log\left(1 - p_i\right) \right) }_\text{Loss function}   +   \underbrace{ \lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization}  \right\}$$&lt;/Small&gt;

&lt;br&gt;

***

- `\(p_i=1/\left(1+\exp\left(-(\beta_0 + x_i^T\beta)\right)\right)\)`

- `\(x\)` is denoting the **C+T scores** and covariates (e.g. principal components), 

- `\(y\)` is the disease status we want to predict, 

- `\(\lambda\)` is a regularization parameter that needs to be determined and

- `\(\alpha\)` determines relative parts of the regularization `\(0 \le \alpha \le 1\)`. 

---

## Results (simulations)

&lt;img src="figures/SCT-AUC-simus.png" width="3480" style="display: block; margin: auto;" /&gt;

---

## Results (real data)

&lt;br&gt;

&lt;img src="figures/SCT-AUC-real.png" width="1047" style="display: block; margin: auto;" /&gt;

---

## Results (optimal parameters in maxCT)

&lt;br&gt;
&lt;br&gt;

&lt;img src="figures/opt-param-maxCT.png" width="120%" style="display: block; margin: auto;" /&gt;

---
class: center, middle, inverse

# Conclusion

---

## My thesis work

&lt;br&gt;

1. Developping two <i class="fab  fa-r-project "></i> packages for the analysis of large-scale genomic data.    

    (https://doi.org/10.1093/bioinformatics/bty185) 
    
    Package bigstatsr can be used for any data encoded as matrices.

2. Including an implementation of penalized regression for very large individual-level datasets \+ assess the potential gain in prediction over the simple standard model (C+T).
    
    (https://doi.org/10.1101/403337) 

3. Including summary statistics from large GWAS to improve prediction. 

    (TODO) 

---

## Make sure to grab an hex sticker

&lt;br&gt;

&lt;img src="https://raw.githubusercontent.com/privefl/bigstatsr/master/bigstatsr.png" width="45%" style="display: block; margin: auto;" /&gt;

---
class: center, middle, inverse

# Thanks!

&lt;br&gt;

Presentation available at

https://privefl.github.io/thesis-docs/defense.html

&lt;br&gt;

<i class="fab  fa-twitter "></i> [privefl](https://twitter.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-github "></i> [privefl](https://github.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-stack-overflow "></i> [F. Privé](https://stackoverflow.com/users/6103040/f-priv%c3%a9)

.footnote[Slides created via R package [**xaringan**](https://github.com/yihui/xaringan).]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
