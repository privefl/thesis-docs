---
title: "Overview of my work"
output:
  xaringan::moon_reader:
    seal: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, width = 70)
knitr::opts_chunk$set(fig.align = 'center', dev = "svg", out.width = "70%",
                      echo = FALSE, comment = "", fig.width = 5, global.par = TRUE)
```

class: title-slide center middle inverse

<br>

# Overview of my work

<br>

## Statistical tools for human genetics

### (focus on prediction and ancestry inference)

<br>

### Florian Privé

---

#### [1] Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr

```{r, out.width="95%"}
knitr::include_graphics("figures/overview-paper1.png")
```

---

#### Main motivations for developing these two packages

<br>

- being able to run all my analyses within `r icon::fa_r_project()`

- frustration of having to use all these different software, with different input formats, and requiring text files for parameters

- simpler to build a chain of analyses, to perform some exploratory analyses, and to use familiar packages

- simpler to develop new methods, thanks to a simple matrix-like format

<br>

--

Note that many functions (to perform e.g. GWAS, PCA, summary statistics) are not really specific to genotype data; I implemented those in {bigstatsr}. 

This is why there are two packages, where {bigstatsr} can basically be used by any field using matrices, while {bigsnpr} provides some tools rather specific to genotype data, largely building on top of {bigstatsr}. 

Learn more about {bigstatsr} and the Filebacked Big Matrix (FBM) format in [this webinar](https://t.co/LUQQp7INlX).

---

#### [2] Efficient Implementation of Penalized Regression for Genetic Risk Prediction

<br>

<Small>$$\arg\!\min_{\beta_0,~\beta}(\lambda, \alpha)\left\{  \underbrace{ \sum_{i=1}^n \left( y_i -(\beta_0 + x_i^T\beta) \right)^2 }_\text{Loss function (linear reg)}   +   \underbrace{ \lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization}  \right\}$$</Small>

<br>

- $x$ is the **genotypes** and covariates (e.g. sex and principal components), 

- $y$ is the trait / disease status we want to predict, 

- $\lambda$ is a regularization parameter that needs to be determined and

- $\alpha$ determines relative parts of the regularization $0 \le \alpha \le 1$. 

<br>

In `r icon::fa_r_project()` package {bigstatsr}, very fast implementation with automatic choice of $\lambda$ and $\alpha$ [[bit.ly/plr-bigstatsr](https://bit.ly/plr-bigstatsr)]

---

#### Penalized linear regression for predicting height from genotypes

<br>

- 350K individuals x 656K variants in less than one day

- Within each both males and females, 65.5% of correlation between predicted and true height

```{r, out.width="75%"}
knitr::include_graphics("https://privefl.github.io/blog/images/UKB-final-pred.png")
```

---

#### [3] Making the Most of Clumping and Thresholding for Polygenic Scores

Hyper-parameters in C+T:

- threshold on squared correlation of clumping (e.g. $r_c^2 > 0.2$) and    
window size for LD computation (e.g. $w_c = 500 kb$)

- p-value threshold ( $p_T$ between $1$ and $10^{-8}$ and choose the best one )

- other parameters such as the threshold of imputation quality score (e.g. $INFO > 0.3$) or minor allele frequency (e.g. $MAF > 0.01$)

$\Longrightarrow$ *stdCT* (standard C+T)

--

<br>

Our contribution:

- an efficient implementation to compute thousands of C+T scores corresponding to different sets of hyper-parameters   
$\Longrightarrow$ *maxCT* (maximized C+T)

- going further by **stacking** with a linear combination of all C+T models (instead of just choosing the best model)    
$\Longrightarrow$ *SCT* (Stacked C+T)

---

#### [4] Performing Highly Efficient Genome Scans for Local Adaptation with R Package pcadapt Version 4

Basically performs a GWAS for population structure $\rightarrow$ faster implementation

```{r, out.width="75%"}
knitr::include_graphics("figures/timings-pcadapt.png")
```

---

#### [5] Efficient toolkit implementing best practices for principal component analysis of population genetic data

PC loadings of the UK Biobank:

```{r, out.width="100%"}
knitr::include_graphics("figures/loadings-ukbb.jpeg")
```

---

#### PCA projection is biased

```{r, out.width="100%"}
knitr::include_graphics("figures/pca-proj.jpeg")
```

PC scores 1–8 of the 1000 Genomes project

- black points: individuals for PCA training (60%)

- red points: simple projection of other individuals

- blue points: corrected projection

---

#### Our proposed pipeline

```{r, out.width="60%"}
knitr::include_graphics("figures/pca-pipeline.jpeg")
```

---

#### [6] Optimal linkage disequilibrium splitting

```{r, out.width="78%"}
knitr::include_graphics("https://github.com/privefl/paper-ldsplit/raw/main/illu.png")
```

$$C(i, k) = \min_j \left\lbrace E(i, j) + C(j + 1, k - 1) \right\rbrace$$
---

#### Portability of 245 polygenic scores when derived from the UK Biobank and applied to 9 ancestry groups from the same cohort

---

LDpred2 [[bit.ly/ldpred2-paper](https://bit.ly/ldpred2-paper)] assumes the following model for effect sizes,

<div class="math">
\[
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0, \frac{h^2}{M p}\right) & \mbox{with probability } p,\\
0 & \mbox{otherwise,}\end{array}
\right.
\]
</div>

where 
- $p$ is the proportion of causal variants, 
- $M$ the number of variants,
- $h^2$ the (SNP) heritability.
- $\gamma$ the effect sizes on the allele scale,
- $\beta$ the effects of the scaled genotypes $\rightarrow S$ is their SD.

<br>

LDpred2 is a polygenic score method (i.e. its primary goal is prediction),    
but LDpred2-auto can estimate $h^2$ and $p$ directly from the data     
(i.e. no extra data is needed to tune these two hyper-parameters).

---

### Introducing the S parameter

<br>

LDpred2 should probably assume instead (the BayesS model)

<div class="math">
\[
\beta_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0, [2 f_j (1 - f_j)]^{S+1} \sigma_\beta^2\right) & \mbox{with probability } p,\\
0 & \mbox{otherwise,}\end{array}
\right.
\]
</div>

<br>

--

- Currently LDpred2 assumes that $S = -1$, i.e. that all causal variants contribute similarly to the heritability on average, whatever their allele frequency $f$. 

- A negative $S$ parameter is often reported as a sign of negative selection.

- $S = 0$ would mean that expected effect sizes (on the allele scale) do not vary with the allele frequencies.

- Should use something in-between?

---


---

class: inverse, center, middle

# Thanks!

<br>

Presentation available at    
https://privefl.github.io/thesis-docs/overview.html

<br>

<br>

`r icon::fa("twitter")` `r icon::fa("github")` privefl

.footnote[Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).]

