<!DOCTYPE html>
<html>
  <head>
    <title>Data Club</title>
    <meta charset="utf-8">
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">




class: title-slide center middle inverse

# High-dimensional data:&lt;br&gt;a different kind of big data

## Florian Privé

### Data Club - June 27, 2018

---

class: center, middle, inverse

# Introduction

---

## The data I work with: very large genotype matrices

&lt;br&gt;

- Each variable (column): number of mutations for **one position of the genome** (generally between 100,000 to several millions) -&gt; **ultra-high dimensional** data

&lt;img src="https://jmtomko.files.wordpress.com/2015/12/dna-double-helix.png" width="70%" style="display: block; margin: auto;" /&gt;

&lt;br&gt;

- Each observation (row): one individual (generally between 1000 and 1M)

.footnote[Example of a dataset I previously worked with: 15K x 280K, [celiac disease](https://doi.org/10.1038/ng.543) (~30GB)]

---

class: center, middle, inverse

# What types of analysis we do?

## (and how?)

---

## Principal Component Analysis (PCA)&lt;br&gt;captures population structure

&lt;br&gt;

&lt;img src="figures/PC-1-2.png" width="70%" style="display: block; margin: auto;" /&gt;

---

## Partial PCA algorithm

&lt;br&gt;

You have a matrix `\(X\)` with `\(n\)` observations (rows) and `\(p\)` variables (columns).

&lt;br&gt;

- Usually, `\(p\)` is small and you can get the SVD from the eigen decomposition of `\(X^T X\)`. In bioinformatics, `\(p\)` is usually too large, so you can't use this standard algorithm.

- If `\(n\)` is not to large (say `\(n &lt; 10,000\)`), you can use the eigen decomposition of `\(X X^T\)` instead (an `\(n \times n\)` matrix). 

- **Now, n is also large** (both dimensions of the matrix are large), so we use algorithms based on random projections to get first PCs (usually we are interested in only first 10-20 PCs).

&lt;br&gt;

With my implementation, you can get first 10 PCs of a 15K x 100K matrix in one minute only.

---

## Still, we can't do PCA naively

&lt;br&gt;

&lt;img src="figures/PC-3-4.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## Cause of the problem

&lt;br&gt;

&lt;img src="figures/load3-3-4.svg" width="78%" style="display: block; margin: auto;" /&gt;

---

## After some filtering

&lt;br&gt;

&lt;img src="figures/PC4-3-4.png" width="80%" style="display: block; margin: auto;" /&gt;

---

## Genome-wide association studies

For linear regression, a t-test is performed **for each variable** `\(j\)` on `\(\beta^{(j)}\)` where
`\begin{multline}
  \hat{y} = \alpha^{(j)} + \beta^{(j)} X^{(j)} + \gamma_1^{(j)} PC_1 + \cdots + \gamma_K^{(j)} PC_K \\ + \delta_1^{(j)} COV_1 + \cdots + \delta_K^{(j)} COV_L~,
\end{multline}`
and `\(K\)` is the number of principal components and `\(L\)` is the number of other covariates (such as age and gender). 

&lt;br&gt;

Similarly, for logistic regression, a Z-test is performed for each variable `\(j\)` on `\(\beta^{(j)}\)` where
`\begin{multline}
  \log{\left(\frac{\hat{p}}{1-\hat{p}}\right)} = \alpha^{(j)} + \beta^{(j)} X^{(j)} + \gamma_1^{(j)} PC_1 + \cdots + \gamma_K^{(j)} PC_K \\ + \delta_1^{(j)} COV_1 + \cdots + \delta_K^{(j)} COV_L~,
\end{multline}`
and `\(\hat{p} = \mathbb{P}(Y = 1)\)` and `\(Y\)` denotes the binary phenotype.

---

## Genome-wide association studies

### Which genes are associated with the disease?

&lt;br&gt;

&lt;img src="figures/celiac-gwas-cut.png" width="80%" style="display: block; margin: auto;" /&gt;

.footnote[Here, you do ~1M tests, so beware **multiple testing**!]

---

## Prediction

Can you fit a statistical learning model when you have more variables than observations ( `\(n &gt; p\)` )?

&lt;br&gt;

### Quiz

How can you fit a prediction model when you have too many variables?

---

## Regularization / Penalization

Minimize

`$$F(\lambda, \alpha) = \text{Loss function}   +   \underbrace{ \lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization}$$`

Different regularizations can be used to make the problem solvable and to prevent overfitting: 

- the L2-regularization ("ridge") shrinks coefficients and is ideal if there are many predictors drawn from a Gaussian distribution (corresponds to `\(\alpha = 0\)` in the previous equation)

- the L1-regularization ("lasso") forces some of the coefficients to be equal to zero and can be used as a means of variable selection, leading to sparse models (corresponds to `\(\alpha = 1\)`)

- the L1- and L2-regularization ("elastic-net") is a compromise between the two previous penalties and is particularly useful in the `\(p \gg n\)` situation, or any situation involving many correlated predictors (corresponds to `\(0 &lt; \alpha &lt; 1\)`).

---

### Predict Celiac disease based on penalized logistic regression

&lt;br&gt;

&lt;img src="figures/density-scores.svg" width="90%" style="display: block; margin: auto;" /&gt;

---

class: center, middle, inverse

# How to analyze large genomic data?

---

## Our two R packages: bigstatsr and bigsnpr

### Statistical tools with big matrices stored on disk

&lt;br&gt;

&lt;a href="https://doi.org/10.1093/bioinformatics/bty185" target="_blank"&gt;
&lt;img src="figures/bty185.png" width="70%" style="display: block; margin: auto;" /&gt;
&lt;/a&gt;

&lt;br&gt;

- {bigstatsr} for many types of matrix, to be used by any field of research

- {bigsnpr} for functions that are specific to the analysis of genetic data

---

class: center, middle, inverse

# High-dimensional data&lt;br&gt;come with their own problems

---

class: center, middle, inverse

# Data are becoming larger and larger

# Will we all need skills in computer science?

---

class: center, middle, inverse

# Thanks!

&lt;br&gt;

Presentation available at

https://privefl.github.io/thesis-docs/data-club.html

&lt;br&gt;

<i class="fab  fa-twitter "></i> [privefl](https://twitter.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-github "></i> [privefl](https://github.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fab  fa-stack-overflow "></i> [F. Privé](https://stackoverflow.com/users/6103040/f-priv%c3%a9)

.footnote[Slides created via R package [**xaringan**](https://github.com/yihui/xaringan).]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
