<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Overview of my work</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/fontawesome-all.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">




class: title-slide center middle inverse

&lt;br&gt;

# Overview of my work

&lt;br&gt;

## Statistical methods &amp; tools for human genetics

### (focus on prediction and ancestry inference)

&lt;br&gt;

### Florian Privé

---

#### [1] Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr

&lt;br&gt;

&lt;img src="https://raw.githubusercontent.com/privefl/R-presentation/master/memory-solution.svg" width="95%" style="display: block; margin: auto;" /&gt;

---

#### Some features of the packages

&lt;img src="figures/overview-paper1.png" width="100%" style="display: block; margin: auto;" /&gt;

---

#### Main motivations for developing these two packages

&lt;br&gt;

- being able to run all my analyses within <i class="fab  fa-r-project "></i>

- frustration of having to use all these different software, with different input formats, and requiring text files for parameters

- simpler to build a chain of analyses, to perform some exploratory analyses, and to use familiar packages

- simpler to develop new methods, thanks to a simple matrix-like format

&lt;br&gt;

--

Note that many functions (to perform e.g. GWAS, PCA, summary statistics) are not really specific to genotype data; I implemented those in {bigstatsr}. 

This is why there are two packages, where {bigstatsr} can basically be used by any field using matrices, while {bigsnpr} provides some tools rather specific to genotype data, largely building on top of {bigstatsr}. 

Learn more about {bigstatsr} and the Filebacked Big Matrix (FBM) format in [this webinar](https://t.co/LUQQp7INlX).

---

#### [2] Efficient Implementation of Penalized Regression for Genetic Risk Prediction

&lt;br&gt;

&lt;Small&gt;$$\arg\!\min_{\beta_0,~\beta}(\lambda, \alpha)\left\{  \underbrace{ \sum_{i=1}^n \left( y_i -(\beta_0 + x_i^T\beta) \right)^2 }_\text{Loss function (linear reg)}   +   \underbrace{ \lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right) }_\text{Penalization}  \right\}$$&lt;/Small&gt;

&lt;br&gt;

- `\(x\)` is the **genotypes** and covariates (e.g. sex and principal components), 

- `\(y\)` is the trait / disease status we want to predict, 

- `\(\lambda\)` is a regularization parameter that needs to be determined and

- `\(\alpha\)` determines relative parts of the regularization `\(0 \le \alpha \le 1\)`. 

&lt;br&gt;

In <i class="fab  fa-r-project "></i> package {bigstatsr}, very fast implementation with automatic choice of `\(\lambda\)` and `\(\alpha\)` [[bit.ly/plr-bigstatsr](https://bit.ly/plr-bigstatsr)]

---

#### Benchmark against snpnet

&lt;img src="figures/snpnet-benchmark.jpg" width="100%" style="display: block; margin: auto;" /&gt;

- 337K individuals (including 20% kept for testing), 504K genotyped variants and 10 cores used

- snpnet uses 60% of the data for initial training, then 80% for refitting (with best hyper-parameters)

- reporting partial correlations, and timings in minutes

- timings for bigstatsr report the time taken by the CMSA procedure (fitting K=4 models here)

.footnote[Our paper was published 1.5y before snpnet, before snpnet was even a preprint.]

---

#### [3] Making the Most of Clumping and Thresholding for Polygenic Scores

Hyper-parameters in C+T:

- threshold on squared correlation of clumping (e.g. `\(r_c^2 &gt; 0.2\)`) and    
window size for LD computation (e.g. `\(w_c = 500 kb\)`)

- p-value threshold ( `\(p_T\)` between `\(1\)` and `\(10^{-8}\)` and choose the best one )

- other parameters such as the threshold of imputation quality score (e.g. `\(INFO &gt; 0.3\)`) or minor allele frequency (e.g. `\(MAF &gt; 0.01\)`)

`\(\Longrightarrow\)` *stdCT* (standard C+T)

--

&lt;br&gt;

Our contribution:

- an efficient implementation to compute thousands of C+T scores corresponding to different sets of hyper-parameters   
`\(\Longrightarrow\)` *maxCT* (maximized C+T)

- going further by **stacking** with a linear combination of all C+T models (instead of just choosing the best model)    
`\(\Longrightarrow\)` *SCT* (Stacked C+T)

---

#### [4] Performing Highly Efficient Genome Scans for Local Adaptation with R Package pcadapt Version 4

Basically performs a GWAS for population structure `\(\rightarrow\)` faster implementation

&lt;img src="figures/timings-pcadapt.png" width="75%" style="display: block; margin: auto;" /&gt;

---

#### [5] Efficient toolkit implementing best practices for principal component analysis of population genetic data

PC loadings of the UK Biobank:

&lt;img src="figures/loadings-ukbb.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---

#### PCA projection is biased

&lt;img src="figures/pca-proj.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

PC scores 1–8 of the 1000 Genomes project

- black points: individuals for PCA training (60%)

- red points: simple projection of other individuals

- blue points: corrected projection

---

#### Our proposed pipeline

&lt;img src="figures/pca-pipeline.jpeg" width="60%" style="display: block; margin: auto;" /&gt;

---

#### [6] LDpred2: better, faster, stronger

&lt;br&gt;

LDpred2 assumes the following model for effect sizes,

&lt;div class="math"&gt;
\[
\beta_j = S_j \gamma_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0, \frac{h^2}{M p}\right) &amp; \mbox{with probability } p,\\
0 &amp; \mbox{otherwise,}\end{array}
\right.
\]
&lt;/div&gt;

where 
- `\(p\)` is the proportion of causal variants, 
- `\(M\)` the number of variants,
- `\(h^2\)` the (SNP) heritability.
- `\(\gamma\)` the effect sizes on the allele scale,
- `\(\beta\)` the effects of the scaled genotypes `\(\rightarrow S\)` is their SD.

&lt;br&gt;

LDpred2 is a polygenic score method (i.e. its primary goal is prediction),    
but LDpred2-auto can estimate `\(h^2\)` and `\(p\)` directly from the data     
(i.e. no extra data is needed to tune these two hyper-parameters).

---

#### LDpred2 is a very competitive PGS method

&lt;br&gt;

&lt;img src="figures/ldpred2-comparison.jpeg" width="100%" style="display: block; margin: auto;" /&gt;

---

#### [7] Optimal linkage disequilibrium splitting

&lt;img src="https://github.com/privefl/paper-ldsplit/raw/main/illu.png" width="78%" style="display: block; margin: auto;" /&gt;

`$$C(i, k) = \min_j \left\lbrace E(i, j) + C(j + 1, k - 1) \right\rbrace$$`
---

#### [8] Portability of 245 polygenic scores when derived from the UK Biobank and applied to 9 ancestry groups from the same cohort

&lt;br&gt;

&lt;img src="https://pbs.twimg.com/media/FIe2G4wWYAEYWwA?format=png&amp;name=4096x4096" width="100%" style="display: block; margin: auto;" /&gt;

---

#### Predictive power decreases with genetic distance to training population

&lt;br&gt;

&lt;img src="https://pbs.twimg.com/media/FIe3e0PXMAQ04rF?format=png&amp;name=large" width="90%" style="display: block; margin: auto;" /&gt;

---

#### [9] Using the UK Biobank as a global reference of worldwide populations: application to measuring ancestry diversity from GWAS summary statistics

&lt;br&gt;

- defined 21 ancestry groups in the UK Biobank (later merged into 18)

- use PCA projection and quadratic programming to infer ancestry proportions from allele frequencies alone

&lt;br&gt;

&lt;img src="figures/ancestry-prop.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

#### [10] Identifying and correcting for misspecifications in GWAS summary statistics and polygenic scores

`$$\text{sd}(G_j) \approx \dfrac{\text{sd}(y)}{\sqrt{n_j ~ \text{se}(\hat{\gamma}_j)^2 + \hat{\gamma}_j^2}}$$`

&lt;img src="https://pbs.twimg.com/media/FMWcONOWUAE6mvr?format=jpg&amp;name=4096x4096" width="100%" style="display: block; margin: auto;" /&gt;

---

#### INFO scores are misestimated for multi-ancestry data

&lt;img src="https://pbs.twimg.com/media/FMWbKkRXEAAFjew?format=jpg&amp;name=4096x4096" width="80%" style="display: block; margin: auto;" /&gt;

---

#### True per-variant sample sizes are better for polygenic scores

&lt;br&gt;

&lt;img src="figures/misspecN.jpg" width="100%" style="display: block; margin: auto;" /&gt;

---

#### An ancestry-matched LD reference is better for polygenic scores

&lt;br&gt;

&lt;img src="https://pbs.twimg.com/media/FMWhYF_XwAA04HY?format=png&amp;name=large" width="100%" style="display: block; margin: auto;" /&gt;

---

#### Overview of some possible misspecifications

&lt;img src="https://pbs.twimg.com/media/FMWZBAlX0AELSLG?format=jpg&amp;name=900x900" width="100%" style="display: block; margin: auto;" /&gt;

---

class: title-slide center middle inverse

## Overview of methods

## and future work

---

#### Overview of methods implemented

&lt;img src="figures/overview-packages.jpg" width="95%" style="display: block; margin: auto;" /&gt;

---

#### References

&lt;style type="text/css"&gt;
.small { font-size: 75% }
&lt;/style&gt;


.small[
[10] Privé, Florian, et al. "Identifying and correcting for misspecifications in GWAS summary statistics and polygenic scores." *bioRxiv* (2022). [[preprint]](https://doi.org/10.1101/2021.03.29.437510)

[9] Privé, Florian. "Using the UK Biobank as a global reference of worldwide populations: application to measuring ancestry diversity from GWAS summary statistics." *bioRxiv* (2022). [[preprint]](https://doi.org/10.1101/2021.10.27.466078)

[8] Privé, Florian, et al. "Portability of 245 polygenic scores when derived from the UK Biobank and applied to 9 ancestry groups from the same cohort." *The American Journal of Human Genetics* 109.1 (2022): 12-23. [[Paper]](https://doi.org/10.1016/j.ajhg.2021.11.008)

[7] Privé, Florian. "Optimal linkage disequilibrium splitting." *Bioinformatics* 38.1 (2022): 255–256. [[Open Access]](https://doi.org/10.1093/bioinformatics/btab519)

[6] Privé, Florian, et al. "LDpred2: better, faster, stronger." *Bioinformatics* 36.22-23 (2020): 5424-5431. [[Open Access]](https://doi.org/10.1093/bioinformatics/btaa1029)

[5] Privé, Florian, et al. "Efficient toolkit implementing best practices for principal component analysis of population genetic data." *Bioinformatics* 36.16 (2020): 4449-4457. [[Open Access]](https://doi.org/10.1093/bioinformatics/btaa520)

[4] Privé, Florian, et al. "Performing highly efficient genome scans for local adaptation with R package pcadapt version 4." *Molecular biology and evolution* 37.7 (2020): 2153-2154. [[Open access]](https://doi.org/10.1093/molbev/msaa053)

[3] Privé, Florian, et al. "Making the most of Clumping and Thresholding for polygenic scores." *The American Journal of Human Genetics* 105.6 (2019): 1213-1221. [[Open access]](https://doi.org/10.1016/j.ajhg.2019.11.001)

[2] Privé, Florian, et al. "Efficient implementation of penalized regression for genetic risk prediction." *Genetics* 212.1 (2019): 65-74. [[Open access]](https://doi.org/10.1534/genetics.119.302019)

[1] Privé, Florian, et al. "Efficient analysis of large-scale genome-wide data with two R packages: bigstatsr and bigsnpr." *Bioinformatics* 34.16 (2018): 2781-2787. [[Open access]](https://doi.org/10.1093/bioinformatics/bty185)

]


---

#### Using LDpred2-auto for inference, and introducing the S parameter

&lt;br&gt;

LDpred2 should probably assume instead (the BayesS model)

&lt;div class="math"&gt;
\[
\beta_j \sim \left\{
\begin{array}{ll}
\mathcal N\left(0, [2 f_j (1 - f_j)]^{S+1} \sigma_\beta^2\right) &amp; \mbox{with probability } p,\\
0 &amp; \mbox{otherwise,}\end{array}
\right.
\]
&lt;/div&gt;

&lt;br&gt;

--

- Currently LDpred2 assumes that `\(S = -1\)`, i.e. that all causal variants contribute similarly to the heritability on average, whatever their allele frequency `\(f\)`.

- A negative `\(S\)` parameter is often reported as a sign of negative selection.

- `\(S = 0\)` would mean that expected effect sizes (on the allele scale) do not vary with the allele frequencies.

- Should use something in-between?

---

#### Extending LDpred2 for multi-ancestry

&lt;br&gt;

TODO


---

class: inverse, center, middle

# Thanks!

&lt;br&gt;

Presentation available at    
https://privefl.github.io/thesis-docs/overview.html

&lt;br&gt;

&lt;br&gt;

<i class="fab  fa-twitter "></i> <i class="fab  fa-github "></i> privefl

.footnote[Slides created with R package [**xaringan**](https://github.com/yihui/xaringan)]

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
