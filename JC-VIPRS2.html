<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>JC_13_Feb_2025</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link rel="shortcut icon" href="#" />
  </head>
  <body>
    <textarea id="source">




class: title-slide center middle inverse

&lt;br&gt;

# Journal Club 13/02/25

## Towards whole-genome inference of polygenic scores&lt;br&gt;with fast and memory-efficient algorithms

&lt;br&gt;

## Florian Priv√© 
### Aarhus University
#### &lt;svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512" width="1em" height="1em"&gt;&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="white"/&gt;&lt;/svg&gt; &lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:white;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; privefl

---

### Abstract

&lt;br&gt;

- developing PRS from millions of variants remain challenging

- people have used either C+T or restricted to 1M HapMap3 variants

- they present a set of algorithmic improvements and compact data structures that enable scaling PRS to use 18M variants

- especially compression of LD matrices (also good for sharing)

- incorporate these changes in their VIPRS method

- now much faster and more memory-efficient

- better prediction when using more variants?

---

### Introduction

&lt;br&gt;

- LD matrices are very large (e.g. 15 GB for 1M variants in LDpred2 with 3cM window; twice if not using the compact format)

- running PGS methods can take up to a few hours for 1M variants

- they propose to

    - quantize and compress LD matrices (size /50)
    
    - assess the spectral properties of different LD matrices
    
    - optimize VIPRS to use the compressed LD matrices
    
    - use two layers of parallelism in VIPRS
    
---

### Efficient LD matrices (methods)

&lt;br&gt;

- two types: either banded (windowed) or block-diagonal (LD blocks)

- can reduce size by

    - storing the upper triangle only (/2)
    
    - storing correlations with less bytes    
    (`\(r^\text{q} = round(r \cdot s)\)` and `\(r^\text{dq} = r^\text{q} / s\)` with `\(s = 127\)` or `\(s = 32767\)`) 
    
    &lt;img src="figures/JC-VIPRS2-table1.png" width="85%" style="display: block; margin: auto;" /&gt;
    
    - storing in compressed chunks (*Zarr* format, also cloud-native) 

---

### Efficient LD matrices (results)

&lt;br&gt;

&lt;img src="figures/JC-VIPRS2-fig2a.png" width="50%" style="display: block; margin: auto;" /&gt;

---

### Optimizations in VIPRS

&lt;br&gt;

- now use C++ instead of Python (speed x10)

- now use optimized matrix operations    
(not sure exactly where, since they use coordinate ascent)

- use 32-bit floats instead of 64-bit doubles for parameters (speed x2!?)

- accommodate the new triangular format for LD + quantized versions

- parallelize over chromosomes (but more memory needed)

- parallelize the coordinate ascent (difficult)

- don't parallelize over LD blocks?    
(want to also accommodate windowed LD)

---

### Investigating numerical instabilities

&lt;br&gt;

- LD is often not positive semi-definite (PSD), i.e. min(eigval) is negative

- the larger are the negative eigenvalues, the more numerical instabilities there are

- three main contributing factors that can impact the spectrum of estimated LD matrices: 

    - sparsification pattern (e.g. windowed, but not LD blocks), 
    
    - pairwise correlation estimator in the presence of missing data    
    (use mean imputation or imputed data instead),
    
    - approximation error (e.g. thresholding or quantization).

--

&lt;br&gt;

- their solution: use `\(\tilde{R} - \min(0, \lambda_\text{min}) I\)` instead of `\(\tilde{R}\)`    
(actually they test {0, 0.01, 0.1, 1, 2} * `\(\lambda_\text{min}\)`)
    
---

### Minimum eigenvalues for block-diagonal LD

&lt;br&gt;

&lt;img src="figures/JC-VIPRS2-figS8b.png" width="90%" style="display: block; margin: auto;" /&gt;

.footnote[MI: mean imputation before computing LD    
(instead of using pairwise complete observations)]

---

### Minimum eigenvalues for windowed LD

&lt;br&gt;

&lt;img src="figures/JC-VIPRS2-figS7a.png" width="100%" style="display: block; margin: auto;" /&gt;

.footnote[LRLD: long-range LD regions (e.g. HLA)]

---

### Numbers of samples and variants

&lt;br&gt;

&lt;img src="figures/JC-VIPRS2-table2.png" width="95%" style="display: block; margin: auto;" /&gt;

--

&lt;br&gt;

Sets of variants considered:

- 18M variants with INFO &gt; 0.8 and MAC &gt; 20 (in the whole cohort &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z"&gt;&lt;/path&gt;&lt;/svg&gt;)

- 13M variants with additionally MAF &gt; 0.1%

- HapMap3+ (1.4M)

---

### Predictive performance

&lt;br&gt;

&lt;img src="figures/JC-VIPRS2-fig4c.png" width="100%" style="display: block; margin: auto;" /&gt;

---

### My thoughts on this paper

What I liked:

- They used many axes of optimization, for both speed and memory

- They looked at different LD matrices and their spectral properties

--

&lt;br&gt;

What I didn't like or didn't understand:

- Runtime results are too-good-to-be-true? e.g. it takes one minute to fit VIPRS on 1.1M variants (uncompressing should take more time)

- I think int8-quantization is too much, but int16 takes 4x more space (because of less efficient compression I guess)

- using more variants may not be beneficial    
when cannot distinguish between correlated variants    
(need e.g. functional annotations and multi-ancestry)

- LD blocks are imperfect, especially for large set of variants

- using one triangle is more difficult for nothing? (compression)

---

class: title-slide center middle inverse

# Any other questions or comments?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
