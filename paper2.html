<!DOCTYPE html>
<html>
  <head>
    <title>Predicting complex diseases: performance and robustness</title>
    <meta charset="utf-8">
    <meta name="author" content="Florian Privé" />
    <meta name="date" content="2018-03-23" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/font-awesome.min.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Predicting complex diseases:<br>performance and robustness
### Florian Privé
### March 23, 2018

---




class: center, middle, inverse

# Introduction

---

## Common diseases

&lt;br&gt;

&lt;img src="http://1.bp.blogspot.com/-7uC6lG9VrBo/ULeG7H8N8TI/AAAAAAAADUQ/0R9aKunBOqs/s1600/F2.medium.gif" width="70%" style="display: block; margin: auto;" /&gt;


.footnote[Source: 10.1126/science.338.6110.1016] 

---

## Polygenic Risk Scores (PRS)

TODO

---

## Polygenic Risk Scores (PRS)

### Use them to identify high risk individuals

&lt;img src="figures/PRS.png" width="95%" style="display: block; margin: auto;" /&gt;

---

## Predictive methods 

### Methods already developed by other people

&lt;br&gt;

- **GWAS + Clumping + Thresholding** (C+T)

- Linear Mixed Models

- Statistical Learning such as 

    - **Logistic Regression**
    
    - Support Vector Machine
    
    - Decision tree methods such as Random Forests

---

## Our two R packages: bigstatsr and bigsnpr

### Statistical tools with big matrices stored on disk

&lt;img src="figures/bigsnpr-submitted.png" width="95%" style="display: block; margin: auto;" /&gt;

- {bigstatsr} for many types of matrix, to be used by any field of research

- {bigsnpr} for functions that are specific to the analysis of genetic data

&lt;br&gt;

Package {bigstatsr} provides a fast penalized logistic regression.

&lt;!-- --- --&gt;

&lt;!-- ## Comparison of the methods --&gt;

&lt;!-- ###  --&gt;

---

class: center, middle, inverse

# Methods

---

## Data

Use real data from a case-control study for the Celiac disease.

&lt;img src="figures/PC1-4.png" width="95%" style="display: block; margin: auto;" /&gt;

Keep only **controls** from the **UK** and **not deviating from the robust Malahanobis distance**.

---

## Simulate new phenotypes

### The liability-threshold model

&lt;img src="figures/LTM.png" width="65%" style="display: block; margin: auto;" /&gt;

---

### Two models of liability

#### A "simple" model

`$$y_i = \underbrace{\sum_{j\in E_\text{causal}} w_j \cdot \widetilde{G_{i,j}}}_\text{genetic effect} + \underbrace{\epsilon_i}_\text{environmental effect}$$` 

#### A "fancy" model

`$$y_i = \underbrace{\sum_{j\in E_\text{causal}^{(1)}} w_j \cdot \widetilde{G_{i,j}}}_\text{linear} + \underbrace{\sum_{j\in E_\text{causal}^{(2)}} w_j \cdot \widetilde{D_{i,j}}}_\text{dominant} + \underbrace{\sum_{\substack{k=1 \\ j_1=e_k^{(3.1)} \\ j_2=e_k^{(3.2)}}}^{k=\left|E_\text{causal}^{(3.1)}\right|} w_{j_1} \cdot \widetilde{G_{i,j_1} G_{i,j_2}}}_\text{interaction} + \epsilon_i$$` 

***

- `\(w_j\)` are **weights** (generated with a Gaussian or a Laplace distribution)
- `\(G_{i,j}\)` is the **allele count** of individual `\(i\)` for SNP `\(j\)`
- `\(D_{i,j} = \mathbf{1}\left\{G_{i,j} \neq 0\right\}\)`

---

## Comprehensive simulations

### Varying many parameters

&lt;br&gt;

&lt;img src="figures/table-scenarios.png" width="95%" style="display: block; margin: auto;" /&gt;

---

## Methods compared

### The C+T method, from GWAS results

&lt;img src="figures/celiac-gwas-cut.png" width="75%" style="display: block; margin: auto;" /&gt;

Pitfalls: weights learned independently and heuristics for correlation and regularization.

`$$S_i(T, E_\text{clumping}) = \sum_{j \in E_\text{clumping}} \mathbf{1}\{p_j &lt; T\} \cdot \beta_j \cdot G_{i,j}$$`

---

## Methods compared

### T-Trees (*Trees inside Trees*) 

- an algorithm derived from random forests 

- takes into account the correlation structure among the genetic markers implied by linkage disequilibrium in GWAS data 

&lt;img src="http://journals.plos.org/plosone/article/figure/image?size=large&amp;id=10.1371/journal.pone.0093379.t004" width="65%" style="display: block; margin: auto;" /&gt;

---

## Methods compared

### Penalized Logistic Regression

&lt;br&gt;

`$$\arg\!\min_{\beta_0, \beta}(x, y, \lambda, \alpha)\left\{\underbrace{\frac{1}{n}\sum_{i=1}^n \log\left(1+e^{-y_i (\beta_0+x_i^T\beta)}\right)}_\text{Loss function} + \underbrace{\lambda \left((1-\alpha)\frac{1}{2}\|\beta\|_2^2 + \alpha \|\beta\|_1\right)}_\text{Penalization}\right\}$$` 

&lt;br&gt;

***

- `\(x\)` is denoting the genotypes and covariables (e.g. principal components), 

- `\(y\)` is the disease status we want to predict, 

- `\(\lambda\)` is a regularization parameter that needs to be determined and

- `\(\alpha\)` determines relative parts of the regularization `\(0 \le \alpha \le 1\)`. 

&lt;!-- --- --&gt;

&lt;!-- ### Different regularizations --&gt;

&lt;!-- Used to prevent overfitting, among other benefits:  --&gt;

&lt;!-- - **the L2-regularization ("ridge") shrinks coefficients** and is ideal if there are many predictors drawn from a Gaussian distribution (corresponds to `\(\alpha = 0\)` in the previous equation); --&gt;

&lt;!-- - **the L1-regularization ("lasso")** forces some of the coefficients to be exactly zero/equal to zero and can be used **as a means of variable selection**, leading to sparse (and therefore more interpretable) models  (corresponds to `\(\alpha = 1\)`);  --&gt;

&lt;!-- - **the L1- and L2-regularization ("elastic-net")** is a compromise between the two previous penalties and is **particularly useful in the `\(m \gg n\)`** situation ($m$: number of SNPs), or any situation involving many correlated predictors (corresponds to `\(0 &lt; \alpha &lt; 1\)`).  --&gt;

&lt;!-- .footnote[In this study, we always use the elastic-net regularization with `\(\alpha = 0.5\)`, without trying to tune (e.g. by grid-search and cross-validation) the value of this hyper-parameter `\(\alpha\)`.] --&gt;

---

### Efficient algorithm


- Strong rules for discarding predictors in lasso-type problems (Tibshirani et al., 2012)

- implemented in R package {biglasso} (Zeng et al., 2017)

- reimplemented in R package {bigstatsr} (Privé et al., 2017) with Cross-Model Selection and Averaging (CMSA):

&lt;br&gt;

&lt;img src="figures/CMSA.png" width="80%" style="display: block; margin: auto;" /&gt;

---

### CMSA: maximization of one model

&lt;br&gt;

&lt;img src="figures/CMSA-one.svg" width="70%" style="display: block; margin: auto;" /&gt;

---

### Extension via feature engineering

We construct a separate dataset with, for each SNP variable, two more variables coding for recessive and dominant effects.

&lt;br&gt;

&lt;img src="figures/triple.svg" width="95%" style="display: block; margin: auto;" /&gt;

&lt;!-- This results in a dataset with 3 times as many variables as the initial one, on which we can apply the penalized logistic regression with the CMSA procedure, as described previously. We call this method "logit-triple" in the results. --&gt;

.footnote[We call these two methods "logit-simple" and "logit-triple".]

---

## Predictive performance measures

AUC (Area Under the ROC Curve) is used.

&lt;img src="https://i.stack.imgur.com/5x3Xj.png" width="45%" style="display: block; margin: auto;" /&gt;

`$$\text{AUC} = P(S_\text{case} &gt; S_\text{control})$$`

.footnote[As a second measure, the partial AUC for specificities between 90% and 100% is also reported.]

---

class: center, middle, inverse

# Results

---

### Higher predictive performance with logit-simple

&lt;br&gt;

&lt;img src="figures/pres-AUC-logit.svg" width="80%" style="display: block; margin: auto;" /&gt;

---

### Predictive performance of C+T method varying with threshold

&lt;br&gt;

&lt;img src="figures/pres-AUC-PRS.svg" width="80%" style="display: block; margin: auto;" /&gt;

---

### T-Trees, not performant enough

&lt;img src="figures/pres-ttrees.svg" width="90%" style="display: block; margin: auto;" /&gt;

---

### Feature engineering improves prediction

&lt;img src="figures/pres-triple.svg" width="90%" style="display: block; margin: auto;" /&gt;

---

### Logit-simple improving faster with increasing sample size

&lt;br&gt;

&lt;img src="figures/pres-AUC-ntrain.svg" width="80%" style="display: block; margin: auto;" /&gt;

---

### logit-simple still winning when using chromosome 6 only

&lt;br&gt;

&lt;img src="figures/pres-AUC-chr6.svg" width="80%" style="display: block; margin: auto;" /&gt;

&lt;!-- .footnote[Aims at increasing the polygenicity of the simulated models and at virtually increasing the sample size.] --&gt;

---

### Results: real Celiac phenotypes

&lt;img src="figures/results-celiac.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="figures/celiac-roc.svg" width="50%" style="display: block; margin: auto;" /&gt;

---

class: center, middle, inverse

# Discussion

---

### Summary of our penalized regression as compared to the C+T method

- A more optimal approach for predicting complex diseases

- linear solution and really sparse 

- even faster

- no need to choose the regularization parameter

- can be extended to capture also recessive and dominant effects

&lt;br&gt;

### Prospects: future work

- use of summary statistics

- generalization on external population

- integration of clinical and environmental data

---

## Future work: UK Biobank

UK Biobank is an extremely large dataset with 

 - genetic data
 
 - clinical data
 
 - environmental data

&lt;br&gt;

## Prospects

- training in one population to improve training and prediction in another population

- assess how can we combine the information provided by genetic data with clinical and environmental data, possibly in a non-linear way

---

class: center, middle, inverse

# Thanks!

&lt;br&gt;

Presentation available at

https://privefl.github.io/thesis-docs/paper2.html

&lt;br&gt;

<i class="fa  fa-twitter "></i> [privefl](https://twitter.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fa  fa-github "></i> [privefl](https://github.com/privefl) &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; <i class="fa  fa-stack-overflow "></i> [F. Privé](https://stackoverflow.com/users/6103040/f-priv%c3%a9)

.footnote[Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).]
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
